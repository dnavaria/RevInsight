# Example spark-defaults.conf for running Spark in Docker

# Application name
spark.app.name                  MySparkApp

# Master URL for the cluster
spark.master                    spark://spark-master:7077

# Memory configuration
spark.executor.memory           2g
spark.driver.memory             1g

# Number of cores to use
spark.executor.cores            1

# Directory to use for "scratch" space in Spark, including map output files and RDDs that get stored on disk
spark.local.dir                 /tmp/spark-temp

# Logging configuration
spark.eventLog.enabled          true
spark.eventLog.dir              /tmp/spark-events

# Checkpoint directory
spark.checkpoint.dir            /tmp/spark-checkpoints
